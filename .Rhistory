pivot_wider(names_from=date, values_from=kwh_per_acc)
# omit na
clus <- na.omit(clus)
clus <- clus %>% relocate(Description, .before = dwelling_type)
saveRDS(clus_data, file = "RDS/clus_data.rds")
saveRDS(clus, file = "RDS/clus.rds")
# clus_data
# clus
# once user have gotten the clustering method from above, they need to input that to find the optimal number of k
clust2 <- hclust(clustering, method = "mcquitty")
library(lubridate)
T3.5 <- read_csv("data/T3-5.csv")
clus_data <- T3.5 %>%
filter(month != "Annual" &
year > 2017 &
dwelling_type != "Overall" &
!str_detect(Description,"Region|Pioneer|Overall"))
# transform dataset
# convert kwh into numbers
clus_data$kwh_per_acc <- as.numeric(clus_data$kwh_per_acc)
# join month and year into a date
clus_data$date <- parse_date_time(paste(clus_data$year, clus_data$month), orders=c("%Y %m"))
# drop month and year column
clus_data <- subset(clus_data, select=-c(month, year, Region)) %>%
arrange(date)
# pivot wider
clus <- clus_data %>%
pivot_wider(names_from=date, values_from=kwh_per_acc)
# omit na
clus <- na.omit(clus)
clus <- clus %>% relocate(Description, .before = dwelling_type)
saveRDS(clus_data, file = "RDS/clus_data.rds")
saveRDS(clus, file = "RDS/clus.rds")
# clus_data
# clus
# once user have gotten the clustering method from above, they need to input that to find the optimal number of k
clust2 <- hclust(clustering, method = "mcquitty")
# once user have gotten the clustering method from above, they need to input that to find the optimal number of k
clus_data <- readRDS(file = "RDS/clus_data.rds") # clustering
clus <- readRDS(file = "RDS/clus.rds") # clustering
clust2 <- hclust(clustering, method = "mcquitty")
library(lubridate)
T3.5 <- read_csv("data/T3-5.csv")
clus_data <- T3.5 %>%
filter(month != "Annual" &
year > 2017 &
dwelling_type != "Overall" &
!str_detect(Description,"Region|Pioneer|Overall"))
# transform dataset
# convert kwh into numbers
clus_data$kwh_per_acc <- as.numeric(clus_data$kwh_per_acc)
# join month and year into a date
clus_data$date <- parse_date_time(paste(clus_data$year, clus_data$month), orders=c("%Y %m"))
# drop month and year column
clus_data <- subset(clus_data, select=-c(month, year, Region)) %>%
arrange(date)
# pivot wider
clus <- clus_data %>%
pivot_wider(names_from=date, values_from=kwh_per_acc)
# omit na
clus <- na.omit(clus)
clus <- clus %>% relocate(Description, .before = dwelling_type)
saveRDS(clus_data, file = "RDS/clus_data.rds")
saveRDS(clus, file = "RDS/clus.rds")
clus_data <- readRDS(file = "RDS/clus_data.rds") # clustering
clus <- readRDS(file = "RDS/clus.rds") # clustering
# clus_data
# clus
clust2 <- hclust(clustering, method = "mcquitty")
library(heatmaply)
clus_group1 <- clus[,-c(2)] %>%
group_by(Description) %>%
summarise_each(list(sum))
# making "Description" the row name (index)
row.names(clus_group1) <- clus_group1$Description
# Making it into a matrix
clus_matrix1 <- data.matrix(clus_group1)
# plot
heatmaply(clus_matrix1[,-c(1)],
scale = "column",
dist_method = "euclidean",
hclust_method = "average",
Colv=NA,
seriate = "none",
k_row = 3,
margins = c(NA,200,50,NA),
colors = viridis(
n= 256, alpha=1,
begin=0, end=1,
option="viridis"),
fontsize_row = 5,
fontsize_col = 5,
main="Hierarchical Clustering",
ylab = "Towns",
xlab = "Time")
clust2 <- hclust(clustering, method = "mcquitty")
# once user have gotten the clustering method from above, they need to input that to find the optimal number of k
library(dendextend)
clustering <- dist(normalize(clus_group1,-c(1)),  method = "maximum")
library(lubridate)
T3.5 <- read_csv("data/T3-5.csv")
clus_data <- T3.5 %>%
filter(month != "Annual" &
year > 2017 &
dwelling_type != "Overall" &
!str_detect(Description,"Region|Pioneer|Overall"))
# transform dataset
# convert kwh into numbers
clus_data$kwh_per_acc <- as.numeric(clus_data$kwh_per_acc)
# join month and year into a date
clus_data$date <- parse_date_time(paste(clus_data$year, clus_data$month), orders=c("%Y %m"))
# drop month and year column
clus_data <- subset(clus_data, select=-c(month, year, Region)) %>%
arrange(date)
# pivot wider
clus <- clus_data %>%
pivot_wider(names_from=date, values_from=kwh_per_acc)
# omit na
clus <- na.omit(clus)
clus <- clus %>% relocate(Description, .before = dwelling_type)
#
# saveRDS(clus_data, file = "RDS/clus_data.rds")
# saveRDS(clus, file = "RDS/clus.rds")
#
# clus_data <- readRDS(file = "RDS/clus_data.rds") # clustering
# clus <- readRDS(file = "RDS/clus.rds") # clustering
# clus_data
# clus
# once user have gotten the clustering method from above, they need to input that to find the optimal number of k
library(dendextend)
clustering <- dist(normalize(clus_group1,-c(1)),  method = "maximum")
library(heatmaply)
clus_group1 <- clus[,-c(2)] %>%
group_by(Description) %>%
summarise_each(list(sum))
# making "Description" the row name (index)
row.names(clus_group1) <- clus_group1$Description
# Making it into a matrix
clus_matrix1 <- data.matrix(clus_group1)
# plot
heatmaply(clus_matrix1[,-c(1)],
scale = "column",
dist_method = "euclidean",
hclust_method = "average",
Colv=NA,
seriate = "none",
k_row = 3,
margins = c(NA,200,50,NA),
colors = viridis(
n= 256, alpha=1,
begin=0, end=1,
option="viridis"),
fontsize_row = 5,
fontsize_col = 5,
main="Hierarchical Clustering",
ylab = "Towns",
xlab = "Time")
# once user have gotten the clustering method from above, they need to input that to find the optimal number of k
library(dendextend)
clustering <- dist(normalize(clus_group1,-c(1)),  method = "maximum")
library(lubridate)
T3.5 <- read_csv("data/T3-5.csv")
clus_data <- T3.5 %>%
filter(month != "Annual" &
year > 2017 &
dwelling_type != "Overall" &
!str_detect(Description,"Region|Pioneer|Overall"))
# transform dataset
# convert kwh into numbers
clus_data$kwh_per_acc <- as.numeric(clus_data$kwh_per_acc)
# join month and year into a date
clus_data$date <- parse_date_time(paste(clus_data$year, clus_data$month), orders=c("%Y %m"))
# drop month and year column
clus_data <- subset(clus_data, select=-c(month, year, Region)) %>%
arrange(date)
# pivot wider
clus <- clus_data %>%
pivot_wider(names_from=date, values_from=kwh_per_acc)
# omit na
clus <- na.omit(clus)
clus <- clus %>% relocate(Description, .before = dwelling_type)
#
# saveRDS(clus_data, file = "RDS/clus_data.rds")
# saveRDS(clus, file = "RDS/clus.rds")
#
# clus_data <- readRDS(file = "RDS/clus_data.rds") # clustering
# clus <- readRDS(file = "RDS/clus.rds") # clustering
# clus_data
# clus
library(heatmaply)
clus_group1 <- clus[,-c(2)] %>%
group_by(Description) %>%
summarise_each(list(sum))
# making "Description" the row name (index)
row.names(clus_group1) <- clus_group1$Description
# Making it into a matrix
clus_matrix1 <- data.matrix(clus_group1)
# plot
heatmaply(clus_matrix1[,-c(1)],
scale = "column",
dist_method = "euclidean",
hclust_method = "average",
Colv=NA,
seriate = "none",
k_row = 3,
margins = c(NA,200,50,NA),
colors = viridis(
n= 256, alpha=1,
begin=0, end=1,
option="viridis"),
fontsize_row = 5,
fontsize_col = 5,
main="Hierarchical Clustering",
ylab = "Towns",
xlab = "Time")
# once user have gotten the clustering method from above, they need to input that to find the optimal number of k
library(dendextend)
clus_group1 <- clus[,-c(2)] %>%
group_by(Description) %>%
summarise_each(list(sum))
clustering <- dist(normalize(clus_group1,-c(1)),  method = "maximum")
packages = c('tidyverse', 'ggstatsplot', 'psych', 'lubridate', 'ggrepel', 'plotly', "tidyr", "readr")
for(p in packages){
if(!require(p,character.only = T)){
install.packages(p)
}
library(p,character.only = T)
}
library(readr)
T2.3 <- read_csv("data/T2-3.csv")
saveRDS(T2.3, file = "RDS/T2-3.rds")
#T2.6 <- read_csv("data/T2-6.csv")
#saveRDS(T2.6, file = "RDS/T2-6.rds")
T3.4 <- read_csv("data/T3-4.csv")
saveRDS(T3.4, file = "RDS/T3-4.rds")
T3.5 <- read_csv("data/T3-5.csv")
saveRDS(T3.5, file = "RDS/T3-5.rds")
T3.6 <- read_csv("data/T3-6.csv")
saveRDS(T3.6, file = "RDS/T3-6.rds")
T3.7 <- read_csv("data/T3-7.csv")
saveRDS(T3.7, file = "RDS/T3-7.rds")
T3.8 <- read_csv("data/T3-8.csv")
saveRDS(T3.8, file = "RDS/T3-8.rds")
T3.9 <- read_csv("data/T3-9.csv")
saveRDS(T3.9, file = "RDS/T3-9.rds")
# T5.1 <- read_csv("data/T5-1.csv")
# saveRDS(T5.1, file = "RDS/T5-1.rds")
#
# T5.2 <- read_csv("data/T5-2.csv")
# saveRDS(T5.2, file = "RDS/T5-2.rds")
#T5.3 <- read_csv("data/T5-3.csv")
#saveRDS(T5.3, file = "RDS/T5-3.rds")
# T5.4 <- read_csv("data/T5-4.csv")
# saveRDS(T5.4, file = "RDS/T5-4.rds")
#
# T5.5 <- read_csv("data/T5-5.csv")
# saveRDS(T5.4, file = "RDS/T5-5.rds")
# Filter the required data for clustering
# remove month = "Annual"
# remove dewlling_type/description = Overall
# year 2018 and onwards due to missing data
# exclude "%region" in description
# Exclude Pioneer as data is incomplete
clus_data <- T3.5 %>%
filter(month != "Annual" &
year > 2017 &
dwelling_type != "Overall" &
!str_detect(Description,"Region|Pioneer|Overall"))
# transform dataset
# convert kwh into numbers
clus_data$kwh_per_acc <- as.numeric(clus_data$kwh_per_acc)
# join month and year into a date
clus_data$date <- parse_date_time(paste(clus_data$year, clus_data$month), orders=c("%Y %m"))
# drop month and year column
clus_data <- subset(clus_data, select=-c(month, year, Region)) %>%
arrange(date)
# pivot wider
clus <- clus_data %>%
pivot_wider(names_from=date, values_from=kwh_per_acc)
# omit na
clus <- na.omit(clus)
clus <- clus %>% relocate(Description, .before = dwelling_type)
# clus_data
# clus
library(heatmaply)
# parameter 1: distance method ("euclidean", "maximum", "manhattan", "canberra", "binary" or "minkowski")
# parameter 2: hclust method ("ward.D", "ward.D2","single","complete","average", "mcquitty", "median" or "centroid")
# parameter 3: number of clusters
# parameter 4: seriate (Optimal leaf ordering, Gruvaeus and Wainer, mean, none)
# parameter 5: scale / normalize / percentize (the code for this part is different)
# Remove dwelling type
clus_group1 <- clus[,-c(2)] %>%
group_by(Description) %>%
summarise_each(list(sum))
# making "Description" the row name (index)
row.names(clus_group1) <- clus_group1$Description
# Making it into a matrix
clus_matrix1 <- data.matrix(clus_group1)
# plot
heatmaply(clus_matrix1[,-c(1)],
scale = "column",
dist_method = "euclidean",
hclust_method = "average",
Colv=NA,
seriate = "none",
k_row = 3,
margins = c(NA,200,50,NA),
colors = viridis(
n= 256, alpha=1,
begin=0, end=1,
option="viridis"),
fontsize_row = 5,
fontsize_col = 5,
main="Hierarchical Clustering",
ylab = "Towns",
xlab = "Time")
# parameter: method
# user will need to input the distance calculated method here to determine which clustering method is optimal
library(dendextend)
clustering <- dist(normalize(clus_group1,-c(1)),  method = "maximum")
packages = c('tidyverse', 'ggstatsplot', 'psych', 'lubridate', 'ggrepel', 'plotly', "tidyr", "readr")
for(p in packages){
if(!require(p,character.only = T)){
install.packages(p)
}
library(p,character.only = T)
}
gc()
packages = c('tidyverse', 'ggstatsplot', 'psych', 'lubridate', 'ggrepel', 'plotly', "tidyr", "readr")
for(p in packages){
if(!require(p,character.only = T)){
install.packages(p)
}
library(p,character.only = T)
}
## Read compressed data file
T2.3 <- readRDS(file = "RDS/T2-3.rds") # Peak System Demand
#T2.6 <- readRDS(file = "RDS/T2-6.rds") # Market Share of Electricity Generation
T3.4 <- readRDS(file = "RDS/T3-4.rds") # Total Household Electricity Consumption by Dwelling Type
T3.5 <- readRDS(file = "RDS/T3-5.rds") # Average Monthly Household Electricity Consumption by Planning Area & Dwelling Type
#T3.6 <- readRDS(file = "RDS/T3-6.rds") # Market Share for Natural Gas Retail
#T3.7 <- readRDS(file = "RDS/T3-7.rds") # Natural Gas Consumption by Sub-Sector
#T3.8 <- readRDS(file = "RDS/T3-8.rds") # Total Household Town Gas Consumption by Dwelling Type
#T3.9 <- readRDS(file = "RDS/T3-9.rds") # Average Monthly Household Town Gas Consumption by Planning Area & Dwelling Type
#T5.1 <- readRDS(file = "RDS/T5-1.rds") # Electricity and Gas Tariffs
#T5.2 <- readRDS(file = "RDS/T5-2.rds") # Monthly Electricity Tariffs (Low Tension Tariffs)
#T5.3 <- readRDS(file = "RDS/T5-3.rds") # Annual Electricity Tariffs by Components (Low Tension Tariffs)
#T5.4 <- readRDS(file = "RDS/T5-4.rds") # Average Monthly Uniform Singapore Energy Prices (USEP)
#T5.5 <- readRDS(file = "RDS/T5-5.rds") # Monthly Town Gas Tariffs
# Filter the required data for clustering
# remove month = "Annual"
# remove dewlling_type/description = Overall
# year 2018 and onwards due to missing data
# exclude "%region" in description
# Exclude Pioneer as data is incomplete
clus_data <- T3.5 %>%
filter(month != "Annual" &
year > 2017 &
dwelling_type != "Overall" &
!str_detect(Description,"Region|Pioneer|Overall"))
# transform dataset
# convert kwh into numbers
clus_data$kwh_per_acc <- as.numeric(clus_data$kwh_per_acc)
# join month and year into a date
clus_data$date <- parse_date_time(paste(clus_data$year, clus_data$month), orders=c("%Y %m"))
# drop month and year column
clus_data <- subset(clus_data, select=-c(month, year, Region)) %>%
arrange(date)
# pivot wider
clus <- clus_data %>%
pivot_wider(names_from=date, values_from=kwh_per_acc)
# omit na
clus <- na.omit(clus)
clus <- clus %>% relocate(Description, .before = dwelling_type)
# clus_data
# clus
library(heatmaply)
# parameter 1: distance method ("euclidean", "maximum", "manhattan", "canberra", "binary" or "minkowski")
# parameter 2: hclust method ("ward.D", "ward.D2","single","complete","average", "mcquitty", "median" or "centroid")
# parameter 3: number of clusters
# parameter 4: seriate (Optimal leaf ordering, Gruvaeus and Wainer, mean, none)
# parameter 5: scale / normalize / percentize (the code for this part is different)
# Remove dwelling type
clus_group1 <- clus[,-c(2)] %>%
group_by(Description) %>%
summarise_each(list(sum))
# making "Description" the row name (index)
row.names(clus_group1) <- clus_group1$Description
# Making it into a matrix
clus_matrix1 <- data.matrix(clus_group1)
# plot
heatmaply(clus_matrix1[,-c(1)],
scale = "column",
dist_method = "euclidean",
hclust_method = "average",
Colv=NA,
seriate = "none",
k_row = 3,
margins = c(NA,200,50,NA),
colors = viridis(
n= 256, alpha=1,
begin=0, end=1,
option="viridis"),
fontsize_row = 5,
fontsize_col = 5,
main="Hierarchical Clustering",
ylab = "Towns",
xlab = "Time")
# parameter: method
# user will need to input the distance calculated method here to determine which clustering method is optimal
library(dendextend)
clustering <- dist(normalize(clus_group1,-c(1)),  method = "maximum")
packages = c('tidyverse', 'ggstatsplot', 'psych', 'lubridate', 'ggrepel', 'plotly', "tidyr", "readr")
for(p in packages){
if(!require(p,character.only = T)){
install.packages(p)
}
library(p,character.only = T)
}
library(readr)
T2.3 <- read_csv("data/T2-3.csv")
saveRDS(T2.3, file = "RDS/T2-3.rds")
#T2.6 <- read_csv("data/T2-6.csv")
#saveRDS(T2.6, file = "RDS/T2-6.rds")
T3.4 <- read_csv("data/T3-4.csv")
saveRDS(T3.4, file = "RDS/T3-4.rds")
T3.5 <- read_csv("data/T3-5.csv")
saveRDS(T3.5, file = "RDS/T3-5.rds")
T3.6 <- read_csv("data/T3-6.csv")
saveRDS(T3.6, file = "RDS/T3-6.rds")
T3.7 <- read_csv("data/T3-7.csv")
saveRDS(T3.7, file = "RDS/T3-7.rds")
T3.8 <- read_csv("data/T3-8.csv")
saveRDS(T3.8, file = "RDS/T3-8.rds")
T3.9 <- read_csv("data/T3-9.csv")
saveRDS(T3.9, file = "RDS/T3-9.rds")
# T5.1 <- read_csv("data/T5-1.csv")
# saveRDS(T5.1, file = "RDS/T5-1.rds")
#
# T5.2 <- read_csv("data/T5-2.csv")
# saveRDS(T5.2, file = "RDS/T5-2.rds")
#T5.3 <- read_csv("data/T5-3.csv")
#saveRDS(T5.3, file = "RDS/T5-3.rds")
# T5.4 <- read_csv("data/T5-4.csv")
# saveRDS(T5.4, file = "RDS/T5-4.rds")
#
# T5.5 <- read_csv("data/T5-5.csv")
# saveRDS(T5.4, file = "RDS/T5-5.rds")
# Filter the required data for clustering
# remove month = "Annual"
# remove dewlling_type/description = Overall
# year 2018 and onwards due to missing data
# exclude "%region" in description
# Exclude Pioneer as data is incomplete
clus_data <- T3.5 %>%
filter(month != "Annual" &
year > 2017 &
dwelling_type != "Overall" &
!str_detect(Description,"Region|Pioneer|Overall"))
# transform dataset
# convert kwh into numbers
clus_data$kwh_per_acc <- as.numeric(clus_data$kwh_per_acc)
# join month and year into a date
clus_data$date <- parse_date_time(paste(clus_data$year, clus_data$month), orders=c("%Y %m"))
# drop month and year column
clus_data <- subset(clus_data, select=-c(month, year, Region)) %>%
arrange(date)
# pivot wider
clus <- clus_data %>%
pivot_wider(names_from=date, values_from=kwh_per_acc)
# omit na
clus <- na.omit(clus)
clus <- clus %>% relocate(Description, .before = dwelling_type)
# clus_data
# clus
library(heatmaply)
# parameter 1: distance method ("euclidean", "maximum", "manhattan", "canberra", "binary" or "minkowski")
# parameter 2: hclust method ("ward.D", "ward.D2","single","complete","average", "mcquitty", "median" or "centroid")
# parameter 3: number of clusters
# parameter 4: seriate (Optimal leaf ordering, Gruvaeus and Wainer, mean, none)
# parameter 5: scale / normalize / percentize (the code for this part is different)
# Remove dwelling type
clus_group1 <- clus[,-c(2)] %>%
group_by(Description) %>%
summarise_each(list(sum))
# making "Description" the row name (index)
row.names(clus_group1) <- clus_group1$Description
# Making it into a matrix
clus_matrix1 <- data.matrix(clus_group1)
# plot
heatmaply(clus_matrix1[,-c(1)],
scale = "column",
dist_method = "euclidean",
hclust_method = "average",
Colv=NA,
seriate = "none",
k_row = 3,
margins = c(NA,200,50,NA),
colors = viridis(
n= 256, alpha=1,
begin=0, end=1,
option="viridis"),
fontsize_row = 5,
fontsize_col = 5,
main="Hierarchical Clustering",
ylab = "Towns",
xlab = "Time")
# parameter: method
# user will need to input the distance calculated method here to determine which clustering method is optimal
library(dendextend)
clustering <- dist(normalize(clus_group1,-c(1)),  method = "maximum")
runApp('Shiny_App_G9')
